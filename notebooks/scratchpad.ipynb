{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from types import TracebackType\n",
    "from typing import AsyncIterator, Generic, List, Optional, Type, TypedDict, TypeVar\n",
    "\n",
    "TSend = TypeVar('TSend', contravariant=True)\n",
    "TYield = TypeVar('TYield', covariant=True)\n",
    "\n",
    "class AsyncGenerator(ABC, AsyncIterator[TYield], Generic[TYield, TSend]):\n",
    "    @abstractmethod\n",
    "    def __aiter__(self) -> AsyncIterator[TYield]:\n",
    "        return self\n",
    "    \n",
    "    @abstractmethod\n",
    "    async def __anext__(self) -> TYield:  # throws: StopAsyncIteration, ...\n",
    "        return await self.asend(None)\n",
    "\n",
    "    @abstractmethod\n",
    "    async def asend(\n",
    "        self,\n",
    "        input: Optional[TSend]\n",
    "    ) -> TYield:  # throws: StopAsyncIteration, ...\n",
    "        ...\n",
    "\n",
    "    @abstractmethod\n",
    "    async def athrow(\n",
    "        self,\n",
    "        exc_type: Type[BaseException],\n",
    "        exc_value: Optional[BaseException] = None,\n",
    "        traceback: Optional[TracebackType] = None,\n",
    "    ) -> Optional[TYield]:  # throws: exc_type, StopAsyncIteration, ...\n",
    "        ...\n",
    "    \n",
    "    @abstractmethod\n",
    "    async def aclose(\n",
    "        self\n",
    "    ) -> None:  # throws RuntimeError, ...\n",
    "        try:\n",
    "            await self.athrow(GeneratorExit)\n",
    "        except (GeneratorExit, StopAsyncIteration):\n",
    "            pass\n",
    "        else:\n",
    "            raise RuntimeError(\"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot create a consistent method resolution\norder (MRO) for bases Generic, MessageMetadata",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 38\u001b[0m\n\u001b[1;32m     34\u001b[0m     role: ChatMLRole \u001b[39m=\u001b[39m ChatMLRole\u001b[39m.\u001b[39mSystem\n\u001b[1;32m     37\u001b[0m TSignal \u001b[39m=\u001b[39m TypeVar(\u001b[39m'\u001b[39m\u001b[39mTSignal\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 38\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mSignal\u001b[39;00m(Generic[TSignal], MessageMetadata):\n\u001b[1;32m     39\u001b[0m     content: TSignal\n\u001b[1;32m     40\u001b[0m     needs_input: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/turbo-chat-aSFXTKLX-py3.8/lib/python3.8/site-packages/pydantic/main.py:282\u001b[0m, in \u001b[0;36mpydantic.main.ModelMetaclass.__new__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/usr/lib/python3.8/abc.py:85\u001b[0m, in \u001b[0;36mABCMeta.__new__\u001b[0;34m(mcls, name, bases, namespace, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__new__\u001b[39m(mcls, name, bases, namespace, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> 85\u001b[0m     \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__new__\u001b[39;49m(mcls, name, bases, namespace, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     86\u001b[0m     _abc_init(\u001b[39mcls\u001b[39m)\n\u001b[1;32m     87\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot create a consistent method resolution\norder (MRO) for bases Generic, MessageMetadata"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from enum import Enum\n",
    "\n",
    "from docarray import BaseDoc\n",
    "from docarray.typing import NdArray\n",
    "from pydantic import Field\n",
    "\n",
    "class ChatMLRole(str, Enum):\n",
    "    System = \"system\"\n",
    "    User = \"user\"\n",
    "    Assistant = \"assistant\"\n",
    "\n",
    "class ChatMLDict(TypedDict):\n",
    "    role: ChatMLRole\n",
    "    content: str\n",
    "\n",
    "class ChatMLMessage(BaseDoc):\n",
    "    role: ChatMLRole\n",
    "    content: str\n",
    "\n",
    "class MessageMetadata(BaseDoc):\n",
    "    timestamp: datetime = Field(default_factory=datetime.now)\n",
    "\n",
    "class Message(ChatMLMessage):\n",
    "    metadata: MessageMetadata = Field(default_factory=MessageMetadata)\n",
    "\n",
    "class User(Message):\n",
    "    role: ChatMLRole = ChatMLRole.User\n",
    "\n",
    "class Assistant(Message):\n",
    "    role: ChatMLRole = ChatMLRole.Assistant\n",
    "\n",
    "class System(Message):\n",
    "    role: ChatMLRole = ChatMLRole.System\n",
    "\n",
    "\n",
    "TSignal = TypeVar('TSignal')\n",
    "class Signal(Generic[TSignal], MessageMetadata):\n",
    "    content: TSignal\n",
    "    needs_input: bool = False\n",
    "    done: bool = False\n",
    "\n",
    "class Start(Signal[TSignal]):\n",
    "    pass\n",
    "\n",
    "class GetInput(Signal[TSignal]):\n",
    "    needs_input: bool = True\n",
    "\n",
    "class Result(Signal[TSignal]):\n",
    "    done: bool = True\n",
    "\n",
    "\n",
    "OPENAI_EMBEDDING_DIMS: int = 1536\n",
    "class EmbeddingMessage(Message):\n",
    "    embedding: NdArray[OPENAI_EMBEDDING_DIMS] = Field(\n",
    "        dims=OPENAI_EMBEDDING_DIMS,\n",
    "        is_embedding=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "from docarray import DocList\n",
    "from docarray.index.abstract import BaseDocIndex\n",
    "from docarray.index.backends.weaviate import WeaviateDocumentIndex\n",
    "from docarray.index.backends.weaviate import EmbeddedOptions\n",
    "\n",
    "cpu_count: int = multiprocessing.cpu_count()\n",
    "\n",
    "dbconfig = WeaviateDocumentIndex.DBConfig(\n",
    "    embedded_options=EmbeddedOptions(\n",
    "        persistence_data_path=\"./.turbo_chat/weaviate-embedded\"\n",
    "    )\n",
    ")\n",
    "\n",
    "batch_config = {\n",
    "    \"batch_size\": 20,\n",
    "    \"dynamic\": True,\n",
    "    \"timeout_retries\": 3,\n",
    "    \"num_workers\": cpu_count // 2,\n",
    "}\n",
    "\n",
    "runtime_config = WeaviateDocumentIndex.RuntimeConfig(batch_config=batch_config)\n",
    "\n",
    "class BaseMemory(DocList[Message]):\n",
    "    index: Optional[BaseDocIndex[Message]] = None\n",
    "\n",
    "    def sorted(self) -> \"BaseMemory\":\n",
    "        return sorted(\n",
    "            self,\n",
    "            key=lambda doc: doc.metadata.timestamp,\n",
    "            reverse=True,\n",
    "        )\n",
    "\n",
    "    async def process(self, **kwargs) -> None:\n",
    "        ...\n",
    "\n",
    "    @abstractmethod\n",
    "    def to_prompt(self, **kwargs) -> List[ChatMLDict]:\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class Memory(BaseMemory):\n",
    "    def to_prompt(self, **kwargs) -> List[ChatMLDict]:\n",
    "        return [\n",
    "            ChatMLDict(role=message.role, content=message.content)\n",
    "            for message in self.sorted()\n",
    "        ]\n",
    "\n",
    "\n",
    "class WeaviateMemory(BaseMemory):\n",
    "    index: WeaviateDocumentIndex[Message] = Field(\n",
    "        default_factory=lambda: WeaviateDocumentIndex[Message](db_config=dbconfig)\n",
    "    )\n",
    "\n",
    "    def __init__(self, **data):\n",
    "        super().__init__(**data)\n",
    "        self.index.configure(runtime_config)\n",
    "\n",
    "    def to_prompt(self, **kwargs) -> List[ChatMLDict]:\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import wraps\n",
    "\n",
    "class TurboGenerator(AsyncGenerator):\n",
    "    def __init__(self, func, *args, **kwargs):\n",
    "        self.args = args\n",
    "        self.kwargs = kwargs\n",
    "        self.func = func\n",
    "        self._gen = func(*args, **kwargs)\n",
    "\n",
    "    def __aiter__(self) -> AsyncIterator[TYield]:\n",
    "        return self._gen\n",
    "    \n",
    "    async def __anext__(self) -> TYield:  # throws: StopAsyncIteration, ...\n",
    "        return await self.asend(None)\n",
    "\n",
    "    async def asend(\n",
    "        self,\n",
    "        input: Optional[TSend] = None,\n",
    "    ) -> TYield:  # throws: StopAsyncIteration, ...\n",
    "        return await self._gen.asend(input)\n",
    "\n",
    "    async def athrow(\n",
    "        self,\n",
    "        exc_type: Type[BaseException],\n",
    "        exc_value: Optional[BaseException] = None,\n",
    "        traceback: Optional[TracebackType] = None,\n",
    "    ) -> Optional[TYield]:  # throws: exc_type, StopAsyncIteration, ...\n",
    "        print(exc_type, exc_value, traceback)\n",
    "    \n",
    "    async def aclose(\n",
    "        self\n",
    "    ) -> None:  # throws RuntimeError, ...\n",
    "        try:\n",
    "            await self.athrow(GeneratorExit)\n",
    "        except (GeneratorExit, StopAsyncIteration):\n",
    "            pass\n",
    "        else:\n",
    "            raise RuntimeError(\"...\")\n",
    "\n",
    "class turbo:\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.args = args\n",
    "        self.kwargs = kwargs\n",
    "\n",
    "    def __call__(self, func):\n",
    "        @wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            turbo_gen = TurboGenerator(func, *self.args, **self.kwargs)\n",
    "            return turbo_gen\n",
    "\n",
    "        return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@turbo()\n",
    "async def turbo_generator():\n",
    "    for i in range(10):\n",
    "        print(i)\n",
    "        yield i\n",
    "\n",
    "gen = turbo_generator()\n",
    "await gen.asend(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "turbo-chat-aSFXTKLX-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
